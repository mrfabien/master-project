{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout\n",
    "import shap\n",
    "import optuna\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "operating_system ='mac'\n",
    "if operating_system == 'win':\n",
    "    path = f'C:/Users/fabau/OneDrive/Documents/GitHub/master-project/'\n",
    "else:\n",
    "    path = f'/Users/fabienaugsburger/Documents/GitHub/master-project/'\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "#import the X and y data in the format .npy\n",
    "dataset = 'X_y_EU_1h'\n",
    "\n",
    "dataset_type = '_all_stat' #all_stat means the 4 stats, 2 means the storms one after another and nothing means only the mean stat\n",
    "\n",
    "X_train = np.load(f'{path}DATASETS/{dataset}/X_train{dataset_type}.npy')\n",
    "y_train = np.load(f'{path}DATASETS/{dataset}/y_train{dataset_type}.npy')\n",
    "X_test = np.load(f'{path}DATASETS/{dataset}/X_test{dataset_type}.npy')\n",
    "y_test = np.load(f'{path}DATASETS/{dataset}/y_test{dataset_type}.npy')\n",
    "X_validation = np.load(f'{path}DATASETS/{dataset}/X_validation{dataset_type}.npy')\n",
    "y_validation = np.load(f'{path}DATASETS/{dataset}/y_validation{dataset_type}.npy')\n",
    "\n",
    "masking_value = 0#2**0.5\n",
    "\n",
    "def preprocess_X_data(X):\n",
    "    # Reshape the X array\n",
    "    reshape = X.reshape(X.shape[0] * X.shape[1], X.shape[2])\n",
    "    \n",
    "    # Fit the StandardScaler to the reshaped X array\n",
    "    reshape_std = StandardScaler().fit_transform(reshape)\n",
    "\n",
    "    # Create the mask indicating where NaN values were originally located\n",
    "    mask_X = np.isnan(X).reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "    \n",
    "    # Replace NaN values with -1e9 in X\n",
    "    reshape_std[np.isnan(reshape_std)] = masking_value\n",
    "    \n",
    "    # Reshape the data back to the original shape for X\n",
    "    X_processed = reshape_std.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "\n",
    "    return X_processed, mask_X\n",
    "\n",
    "def preprocess_y_data(y):\n",
    "    # Reshape the y array\n",
    "\n",
    "    if dataset_type == '_all_stat':\n",
    "        reshape = y.reshape(y.shape[0] * y.shape[1], y.shape[2])\n",
    "\n",
    "        mask_y = np.isnan(y).reshape(y.shape[0], y.shape[1], y.shape[2])\n",
    "\n",
    "        # Replace NaN values with -1e9 in X\n",
    "        reshape[np.isnan(reshape)] = masking_value\n",
    "        \n",
    "        # Reshape the y array\n",
    "        y_processed = reshape.reshape(y.shape[0], y.shape[1], y.shape[2])\n",
    "    else:\n",
    "\n",
    "    #reshape = y.reshape(y.shape[0] * y.shape[1], 1)\n",
    "\n",
    "    # Fit the StandardScaler to the y array\n",
    "    #reshape_std = StandardScaler().fit_transform(reshape)\n",
    "\n",
    "    # Create the mask indicating where NaN values were originally located\n",
    "        mask_y = np.isnan(y).reshape(y.shape[0], y.shape[1])\n",
    "\n",
    "        # Replace NaN values with -1e9 in X\n",
    "        y[np.isnan(y)] = masking_value\n",
    "        \n",
    "        # Reshape the y array\n",
    "        y_processed = y.reshape(y.shape[0], y.shape[1], 1)\n",
    "    \n",
    "    return y_processed, mask_y\n",
    "\n",
    "X_train, M_X_train = preprocess_X_data(X_train)\n",
    "X_test, M_X_test = preprocess_X_data(X_test)\n",
    "X_validation, M_X_validation = preprocess_X_data(X_validation)\n",
    "\n",
    "'''if dataset_type == '0':\n",
    "    y_train, M_y_train = preprocess_X_data(y_train)\n",
    "    y_test, M_y_test = preprocess_X_data(y_test)\n",
    "    y_validation, M_y_validation = preprocess_X_data(y_validation)'''\n",
    "\n",
    "y_train, M_y_train = preprocess_y_data(y_train)\n",
    "y_test, M_y_test = preprocess_y_data(y_test)\n",
    "y_validation, M_y_validation = preprocess_y_data(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabienaugsburger/anaconda3/envs/tensor_flow/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">328,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m30,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m24,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m328,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │         \u001b[38;5;34m1,028\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384,932</span> (1.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m384,932\u001b[0m (1.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384,932</span> (1.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m384,932\u001b[0m (1.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the custom WeightedMSE class\n",
    "class WeightedMSE(tf.keras.losses.Loss):\n",
    "    \"\"\" \n",
    "    Calculate a weighted MSE. This loss gives you control to weight the \n",
    "    pixels that are > 0 differently than the pixels that are 0 in y_true. This\n",
    "    class is subclassed from tf.keras.lossess.Loss to hopefully enable \n",
    "    'stateful'-ness.\n",
    " \n",
    "    weights[0] is the weight for non-zero pixels\n",
    "    weights[1] is the weight for zero pixels.\n",
    "    \"\"\"\n",
    "    def __init__(self, weights=[1.0, 1.0], name=\"custom_mse\", **kwargs):\n",
    "        super(WeightedMSE, self).__init__(name=name, **kwargs)\n",
    "        # store weights\n",
    "        self.w1 = weights[0]\n",
    "        self.w2 = weights[1]\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # build weight_matrix \n",
    "        ones_array = tf.ones_like(y_true)\n",
    "        weights_for_nonzero = tf.math.multiply(ones_array, self.w1)\n",
    "        weights_for_zero = tf.math.multiply(ones_array, self.w2)\n",
    "        weight_matrix = tf.where(tf.greater(y_true, 0), weights_for_nonzero, weights_for_zero)\n",
    "        loss = tf.math.reduce_mean(tf.math.multiply(weight_matrix, tf.math.square(tf.math.subtract(y_pred, y_true))))\n",
    "        return loss\n",
    "\n",
    "# Define the model\n",
    "model_WSE_G = Sequential()\n",
    "\n",
    "# Define the input shape in the first layer of the neural network\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Add a Conv1D layer with 32 filters and a kernel size of 3\n",
    "model_WSE_G.add(Conv1D(filters=32, kernel_size=3, padding='same', input_shape=input_shape))\n",
    "\n",
    "# Add a Dropout layer\n",
    "model_WSE_G.add(Dropout(0.1))\n",
    "\n",
    "# Add the first LSTM layer with 128 units\n",
    "model_WSE_G.add(LSTM(units=64, return_sequences=True))\n",
    "\n",
    "# Add a Dropout layer\n",
    "model_WSE_G.add(Dropout(0.1))\n",
    "\n",
    "# Add the second LSTM layer with 256 units\n",
    "model_WSE_G.add(LSTM(units=256, return_sequences=True))\n",
    "\n",
    "# Add a Dropout layer\n",
    "model_WSE_G.add(Dropout(0.1))\n",
    "\n",
    "# Add a Dense (fully connected) layer with 4 units (for 4 stats)\n",
    "#model_WSE_G.add(Dense(units=128, activation='tanh'))\n",
    "\n",
    "# Add a Flatten layer\n",
    "#model_WSE_G.add(Flatten())\n",
    "\n",
    "# Add the final Dense layer with a linear activation function\n",
    "\n",
    "#output_length = 185\n",
    "model_WSE_G.add(Dense(units=4, activation='linear'))\n",
    "\n",
    "# Compile the model with the custom weighted MSE loss\n",
    "custom_loss = WeightedMSE(weights=[1.0, 0])\n",
    "model_WSE_G.compile(optimizer='adam', loss=custom_loss)\n",
    "\n",
    "# Print the model summary\n",
    "model_WSE_G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./LSTM_3d_WSE_logs_2/run_001\n"
     ]
    }
   ],
   "source": [
    "run_index = 1 # it should be an integer, e.g. 1\n",
    "\n",
    "run_logdir = os.path.join(os.curdir, \"LSTM_3d_WSE_logs_2/\", \"run_{:03d}\".format(run_index))\n",
    "\n",
    "print(run_logdir)\n",
    "\n",
    "# Define callbacks (they can really improve the accuracy if well-chosen!)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"model_WSE_G_2.keras\", \n",
    "                                                   save_best_only=True,\n",
    "                                                   monitor='loss')\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - loss: 101.7034 - val_loss: 113.9364\n",
      "Epoch 2/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 95.2394 - val_loss: 101.9133\n",
      "Epoch 3/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 83.9195 - val_loss: 77.9188\n",
      "Epoch 4/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 64.4692 - val_loss: 58.0436\n",
      "Epoch 5/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 49.0314 - val_loss: 47.2626\n",
      "Epoch 6/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 39.0226 - val_loss: 38.7820\n",
      "Epoch 7/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 32.4321 - val_loss: 32.4140\n",
      "Epoch 8/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 28.1180 - val_loss: 27.9802\n",
      "Epoch 9/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 24.8035 - val_loss: 24.9249\n",
      "Epoch 10/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 22.1155 - val_loss: 22.7505\n",
      "Epoch 11/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 20.4535 - val_loss: 21.1547\n",
      "Epoch 12/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 20.1784 - val_loss: 19.9441\n",
      "Epoch 13/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 18.1514 - val_loss: 19.0059\n",
      "Epoch 14/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 17.5427 - val_loss: 18.2769\n",
      "Epoch 15/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 17.5510 - val_loss: 17.7130\n",
      "Epoch 16/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 17.0183 - val_loss: 17.2883\n",
      "Epoch 17/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 17.2697 - val_loss: 16.9709\n",
      "Epoch 18/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 16.3149 - val_loss: 16.7230\n",
      "Epoch 19/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 15.9781 - val_loss: 16.5210\n",
      "Epoch 20/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 16.0193 - val_loss: 16.3499\n",
      "Epoch 21/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 16.6267 - val_loss: 16.2058\n",
      "Epoch 22/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 16.2063 - val_loss: 16.0838\n",
      "Epoch 23/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 16.1542 - val_loss: 15.9830\n",
      "Epoch 24/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 15.7990 - val_loss: 15.8939\n",
      "Epoch 25/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 15.2470 - val_loss: 15.8071\n",
      "Epoch 26/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 15.9657 - val_loss: 15.7208\n",
      "Epoch 27/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 15.4692 - val_loss: 15.6397\n",
      "Epoch 28/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 14.4581 - val_loss: 15.5620\n",
      "Epoch 29/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 14.4270 - val_loss: 15.4801\n",
      "Epoch 30/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 15.0638 - val_loss: 15.3864\n",
      "Epoch 31/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 15.3887 - val_loss: 15.2727\n",
      "Epoch 32/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 14.1233 - val_loss: 15.1391\n",
      "Epoch 33/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 14.6498 - val_loss: 14.9969\n",
      "Epoch 34/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 14.3969 - val_loss: 14.8496\n",
      "Epoch 35/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 13.9451 - val_loss: 14.6886\n",
      "Epoch 36/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 14.0255 - val_loss: 14.5188\n",
      "Epoch 37/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 13.6105 - val_loss: 14.3312\n",
      "Epoch 38/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 14.0057 - val_loss: 14.1150\n",
      "Epoch 39/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 13.2850 - val_loss: 13.8688\n",
      "Epoch 40/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 13.6991 - val_loss: 13.5925\n",
      "Epoch 41/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 12.9727 - val_loss: 13.2876\n",
      "Epoch 42/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 12.7245 - val_loss: 12.9622\n",
      "Epoch 43/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 11.3514 - val_loss: 12.6212\n",
      "Epoch 44/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 11.7649 - val_loss: 12.2635\n",
      "Epoch 45/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 11.3553 - val_loss: 11.8981\n",
      "Epoch 46/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 11.1193 - val_loss: 11.5301\n",
      "Epoch 47/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 9.9118 - val_loss: 11.1471\n",
      "Epoch 48/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 9.4436 - val_loss: 10.7455\n",
      "Epoch 49/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 9.2815 - val_loss: 10.3299\n",
      "Epoch 50/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 8.4835 - val_loss: 9.8667\n",
      "Epoch 51/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 8.4532 - val_loss: 9.3495\n",
      "Epoch 52/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 7.9818 - val_loss: 8.7849\n",
      "Epoch 53/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 7.7135 - val_loss: 8.1931\n",
      "Epoch 54/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 7.1893 - val_loss: 7.6080\n",
      "Epoch 55/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 6.9400 - val_loss: 7.1627\n",
      "Epoch 56/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 6.7972 - val_loss: 6.8345\n",
      "Epoch 57/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 6.3486 - val_loss: 6.5505\n",
      "Epoch 58/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 5.6917 - val_loss: 6.3667\n",
      "Epoch 59/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 5.6684 - val_loss: 6.2462\n",
      "Epoch 60/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 5.6096 - val_loss: 6.1027\n",
      "Epoch 61/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 5.2823 - val_loss: 5.9213\n",
      "Epoch 62/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 5.1217 - val_loss: 5.7413\n",
      "Epoch 63/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4.8062 - val_loss: 5.6370\n",
      "Epoch 64/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 4.9508 - val_loss: 5.5265\n",
      "Epoch 65/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4.7597 - val_loss: 5.4184\n",
      "Epoch 66/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4.4235 - val_loss: 5.3685\n",
      "Epoch 67/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 4.2673 - val_loss: 5.3001\n",
      "Epoch 68/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4.3925 - val_loss: 5.2108\n",
      "Epoch 69/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 3.9520 - val_loss: 5.1099\n",
      "Epoch 70/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 3.8399 - val_loss: 4.9993\n",
      "Epoch 71/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 3.8381 - val_loss: 4.8718\n",
      "Epoch 72/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 3.5837 - val_loss: 4.7658\n",
      "Epoch 73/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 3.4547 - val_loss: 4.6806\n",
      "Epoch 74/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 3.5155 - val_loss: 4.6008\n",
      "Epoch 75/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 3.4426 - val_loss: 4.5033\n",
      "Epoch 76/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 3.2282 - val_loss: 4.4116\n",
      "Epoch 77/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 3.1314 - val_loss: 4.3039\n",
      "Epoch 78/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 3.1015 - val_loss: 4.1763\n",
      "Epoch 79/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 3.0788 - val_loss: 4.0923\n",
      "Epoch 80/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 3.0998 - val_loss: 4.0372\n",
      "Epoch 81/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 2.8433 - val_loss: 3.9648\n",
      "Epoch 82/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 2.8234 - val_loss: 3.8792\n",
      "Epoch 83/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 2.7320 - val_loss: 3.8226\n",
      "Epoch 84/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 2.7308 - val_loss: 3.7997\n",
      "Epoch 85/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 2.6009 - val_loss: 3.7404\n",
      "Epoch 86/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 2.5063 - val_loss: 3.6238\n",
      "Epoch 87/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 2.5244 - val_loss: 3.5212\n",
      "Epoch 88/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.5700 - val_loss: 3.4875\n",
      "Epoch 89/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 2.4214 - val_loss: 3.4664\n",
      "Epoch 90/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.2996 - val_loss: 3.4093\n",
      "Epoch 91/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 2.3488 - val_loss: 3.3221\n",
      "Epoch 92/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 2.2765 - val_loss: 3.2149\n",
      "Epoch 93/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 2.2578 - val_loss: 3.1406\n",
      "Epoch 94/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 2.2284 - val_loss: 3.0789\n",
      "Epoch 95/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 2.1715 - val_loss: 3.0202\n",
      "Epoch 96/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 2.2841 - val_loss: 3.0623\n",
      "Epoch 97/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.0481 - val_loss: 3.0495\n",
      "Epoch 98/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 2.0908 - val_loss: 2.9881\n",
      "Epoch 99/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 2.1290 - val_loss: 2.8857\n",
      "Epoch 100/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 2.0264 - val_loss: 2.9314\n",
      "Epoch 101/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 2.0231 - val_loss: 2.9970\n",
      "Epoch 102/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 1.9289 - val_loss: 2.9485\n",
      "Epoch 103/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.9509 - val_loss: 2.8570\n",
      "Epoch 104/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 1.9306 - val_loss: 2.8058\n",
      "Epoch 105/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 1.9260 - val_loss: 2.8016\n",
      "Epoch 106/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 1.8953 - val_loss: 2.8152\n",
      "Epoch 107/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 1.8220 - val_loss: 2.8173\n",
      "Epoch 108/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 1.7901 - val_loss: 2.8007\n",
      "Epoch 109/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 1.8056 - val_loss: 2.8003\n",
      "Epoch 110/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 1.7543 - val_loss: 2.7775\n",
      "Epoch 111/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 1.7771 - val_loss: 2.7411\n",
      "Epoch 112/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 1.7856 - val_loss: 2.7179\n",
      "Epoch 113/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 1.7999 - val_loss: 2.7039\n",
      "Epoch 114/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 1.7143 - val_loss: 2.7224\n",
      "Epoch 115/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.7301 - val_loss: 2.7558\n",
      "Epoch 116/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 1.6615 - val_loss: 2.7066\n",
      "Epoch 117/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.6936 - val_loss: 2.6509\n",
      "Epoch 118/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 1.6755 - val_loss: 2.6539\n",
      "Epoch 119/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 1.5921 - val_loss: 2.7236\n",
      "Epoch 120/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.5770 - val_loss: 2.7278\n",
      "Epoch 121/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 1.6670 - val_loss: 2.6577\n",
      "Epoch 122/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.6191 - val_loss: 2.6048\n",
      "Epoch 123/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.5823 - val_loss: 2.6317\n",
      "Epoch 124/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.6184 - val_loss: 2.6457\n",
      "Epoch 125/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.5377 - val_loss: 2.6311\n",
      "Epoch 126/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 1.5500 - val_loss: 2.6069\n",
      "Epoch 127/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 1.5644 - val_loss: 2.6465\n",
      "Epoch 128/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 1.5643 - val_loss: 2.6790\n",
      "Epoch 129/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 1.5792 - val_loss: 2.6710\n",
      "Epoch 130/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 1.5269 - val_loss: 2.6012\n",
      "Epoch 131/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.5626 - val_loss: 2.5849\n",
      "Epoch 132/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.5253 - val_loss: 2.6434\n",
      "Epoch 133/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 1.5500 - val_loss: 2.6341\n",
      "Epoch 134/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 1.5194 - val_loss: 2.5842\n",
      "Epoch 135/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 1.5027 - val_loss: 2.5603\n",
      "Epoch 136/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 1.4631 - val_loss: 2.5722\n",
      "Epoch 137/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 1.4739 - val_loss: 2.6210\n",
      "Epoch 138/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 1.5163 - val_loss: 2.6167\n",
      "Epoch 139/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 1.4793 - val_loss: 2.5782\n",
      "Epoch 140/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 1.4548 - val_loss: 2.5615\n",
      "Epoch 141/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 1.4526 - val_loss: 2.5434\n",
      "Epoch 142/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 1.4671 - val_loss: 2.5389\n",
      "Epoch 143/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 1.4471 - val_loss: 2.5541\n",
      "Epoch 144/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 1.4890 - val_loss: 2.5598\n",
      "Epoch 145/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 1.4340 - val_loss: 2.5622\n",
      "Epoch 146/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 1.3921 - val_loss: 2.5467\n",
      "Epoch 147/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.3630 - val_loss: 2.5428\n",
      "Epoch 148/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 1.4016 - val_loss: 2.5425\n",
      "Epoch 149/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.3585 - val_loss: 2.5473\n",
      "Epoch 150/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 1.4416 - val_loss: 2.5547\n",
      "Epoch 151/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 1.4039 - val_loss: 2.5424\n",
      "Epoch 152/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 1.3871 - val_loss: 2.5542\n",
      "Epoch 153/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.3584 - val_loss: 2.5298\n",
      "Epoch 154/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 1.3365 - val_loss: 2.5630\n",
      "Epoch 155/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 1.3392 - val_loss: 2.6192\n",
      "Epoch 156/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 1.3825 - val_loss: 2.6249\n",
      "Epoch 157/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 1.4068 - val_loss: 2.5352\n",
      "Epoch 158/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 1.3356 - val_loss: 2.4595\n",
      "Epoch 159/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 1.3451 - val_loss: 2.4225\n",
      "Epoch 160/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.3413 - val_loss: 2.4069\n",
      "Epoch 161/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 1.3318 - val_loss: 2.4846\n",
      "Epoch 162/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.3392 - val_loss: 2.4982\n",
      "Epoch 163/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 1.3287 - val_loss: 2.4972\n",
      "Epoch 164/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.2940 - val_loss: 2.4635\n",
      "Epoch 165/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.2869 - val_loss: 2.4212\n",
      "Epoch 166/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 1.2895 - val_loss: 2.4302\n",
      "Epoch 167/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 1.2862 - val_loss: 2.4862\n",
      "Epoch 168/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.3029 - val_loss: 2.4739\n",
      "Epoch 169/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.3433 - val_loss: 2.5138\n",
      "Epoch 170/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.3269 - val_loss: 2.5264\n",
      "Epoch 171/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2978 - val_loss: 2.4752\n",
      "Epoch 172/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.2506 - val_loss: 2.4404\n",
      "Epoch 173/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2895 - val_loss: 2.4185\n",
      "Epoch 174/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.2378 - val_loss: 2.4693\n",
      "Epoch 175/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 1.2794 - val_loss: 2.4975\n",
      "Epoch 176/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 1.2380 - val_loss: 2.4879\n",
      "Epoch 177/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 1.2788 - val_loss: 2.4789\n",
      "Epoch 178/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 1.2540 - val_loss: 2.4768\n",
      "Epoch 179/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 1.2868 - val_loss: 2.4523\n",
      "Epoch 180/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 1.2464 - val_loss: 2.4119\n",
      "Epoch 181/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 1.2363 - val_loss: 2.3831\n",
      "Epoch 182/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 1.2359 - val_loss: 2.4364\n",
      "Epoch 183/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.2486 - val_loss: 2.4912\n",
      "Epoch 184/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.2303 - val_loss: 2.4457\n",
      "Epoch 185/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.2186 - val_loss: 2.4056\n",
      "Epoch 186/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 1.2346 - val_loss: 2.4168\n",
      "Epoch 187/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 1.2164 - val_loss: 2.4029\n",
      "Epoch 188/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 1.2288 - val_loss: 2.3465\n",
      "Epoch 189/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 1.1820 - val_loss: 2.3235\n",
      "Epoch 190/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 1.2208 - val_loss: 2.3869\n",
      "Epoch 191/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 1.2335 - val_loss: 2.4013\n",
      "Epoch 192/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.1823 - val_loss: 2.3858\n",
      "Epoch 193/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.1930 - val_loss: 2.4207\n",
      "Epoch 194/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 1.1661 - val_loss: 2.3715\n",
      "Epoch 195/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.1917 - val_loss: 2.3614\n",
      "Epoch 196/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.2050 - val_loss: 2.4549\n",
      "Epoch 197/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 1.2169 - val_loss: 2.4273\n",
      "Epoch 198/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 1.1860 - val_loss: 2.3806\n",
      "Epoch 199/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.1527 - val_loss: 2.3653\n",
      "Epoch 200/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.1766 - val_loss: 2.3300\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n"
     ]
    }
   ],
   "source": [
    "# try to use the fit the model\n",
    "\n",
    "# Entraîner le modèle\n",
    "model_WSE_G.fit(X_train, y_train,\n",
    "            validation_data=(X_test, y_test), \n",
    "            epochs=200, \n",
    "            verbose=1,  \n",
    "            batch_size=33,\n",
    "            callbacks=[early_stopping_cb, checkpoint_cb, tensorboard_cb],)\n",
    "          #use_multiprocessing=True)\n",
    "\n",
    "# Faire des prédictions\n",
    "y_pred = model_WSE_G.predict(X_test)#.reshape(y_test.shape[0],y_test.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = model_Gia_3d.predict(X_test)\n",
    "'''\n",
    "value_to_replace = -1e9\n",
    "new_value = 0\n",
    "\n",
    "y_test_reshaped = y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
    "\n",
    "y_test_0 = [new_value if x == value_to_replace else x for x in y_test_reshaped]\n",
    "y_test_0 = np.array(y_test_0)\n",
    "\n",
    "y_test_0 = y_test_0.reshape(y_test.shape[0],y_test.shape[1])\n",
    "'''\n",
    "stats = ['max','min','mean','std']\n",
    "colors = ['red', 'green', 'orange', 'blue']\n",
    "for storm_n in range(0,len(y_pred)):\n",
    "    for stat in stats:\n",
    "        num_stat = stats.index(stat)\n",
    "                # Find the index where len(y_test[storm_n, :, num_stat] == 0) is zero\n",
    "        indices = np.where(y_test[storm_n, :, num_stat] == 0)[0]-1\n",
    "        if len(indices) > 0:\n",
    "            xlim_index = indices[0]\n",
    "        else:\n",
    "            xlim_index = len(y_test[storm_n, :, num_stat])\n",
    "        color = colors[num_stat % len(colors)]\n",
    "        plt.plot(y_pred[storm_n, :, num_stat], label=f'y_pred_{stat}', linestyle='--', color=color, alpha=0.7)\n",
    "        plt.plot(y_test[storm_n, :, num_stat], label=f'y_test_{stat}', color=color)\n",
    "        plt.xlim(0,xlim_index)\n",
    "        plt.xlabel('Time steps')\n",
    "        plt.ylabel('Wind gust speed (m/s)')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# calculate the RMSE\n",
    "\n",
    "rms = (mean_squared_error(y_test[:,:xlim_index,:].ravel(),y_pred[:,:xlim_index,:].ravel()))**0.5\n",
    "print(rms) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:28:19,563] A new study created in memory with name: no-name-3d05ab76-0418-4b58-b1bd-99c243fffa2f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.2783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:28:34,643] Trial 0 finished with value: 8.278313636779785 and parameters: {'filters': 52, 'kernel_size': 4, 'dropout_rate': 0.4852181833993443, 'lstm_units_1': 37, 'lstm_units_2': 131}. Best is trial 0 with value: 8.278313636779785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.2415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:28:50,421] Trial 1 finished with value: 4.241499900817871 and parameters: {'filters': 42, 'kernel_size': 2, 'dropout_rate': 0.23615421852547658, 'lstm_units_1': 90, 'lstm_units_2': 172}. Best is trial 1 with value: 4.241499900817871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 12.6386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:29:05,085] Trial 2 finished with value: 12.638574600219727 and parameters: {'filters': 45, 'kernel_size': 2, 'dropout_rate': 0.11499364603989122, 'lstm_units_1': 32, 'lstm_units_2': 105}. Best is trial 1 with value: 4.241499900817871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.9952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:29:20,385] Trial 3 finished with value: 4.995203018188477 and parameters: {'filters': 17, 'kernel_size': 2, 'dropout_rate': 0.40517422048090856, 'lstm_units_1': 82, 'lstm_units_2': 149}. Best is trial 1 with value: 4.241499900817871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 11.2798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:29:34,237] Trial 4 finished with value: 11.27978515625 and parameters: {'filters': 56, 'kernel_size': 5, 'dropout_rate': 0.2806935076831752, 'lstm_units_1': 86, 'lstm_units_2': 94}. Best is trial 1 with value: 4.241499900817871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 33.1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:29:47,900] Trial 5 finished with value: 33.13215255737305 and parameters: {'filters': 36, 'kernel_size': 2, 'dropout_rate': 0.35338692207692124, 'lstm_units_1': 83, 'lstm_units_2': 40}. Best is trial 1 with value: 4.241499900817871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8.7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:30:02,280] Trial 6 finished with value: 8.786049842834473 and parameters: {'filters': 59, 'kernel_size': 5, 'dropout_rate': 0.289060162151947, 'lstm_units_1': 70, 'lstm_units_2': 104}. Best is trial 1 with value: 4.241499900817871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:30:17,013] Trial 7 finished with value: 7.062164306640625 and parameters: {'filters': 30, 'kernel_size': 4, 'dropout_rate': 0.4576686626422082, 'lstm_units_1': 68, 'lstm_units_2': 124}. Best is trial 1 with value: 4.241499900817871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.2068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:30:30,787] Trial 8 finished with value: 5.206752777099609 and parameters: {'filters': 52, 'kernel_size': 5, 'dropout_rate': 0.4926636365037803, 'lstm_units_1': 78, 'lstm_units_2': 156}. Best is trial 1 with value: 4.241499900817871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.4093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:30:45,870] Trial 9 finished with value: 7.40926456451416 and parameters: {'filters': 36, 'kernel_size': 3, 'dropout_rate': 0.3130426761274748, 'lstm_units_1': 50, 'lstm_units_2': 131}. Best is trial 1 with value: 4.241499900817871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.5998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:31:01,773] Trial 10 finished with value: 2.5998289585113525 and parameters: {'filters': 24, 'kernel_size': 3, 'dropout_rate': 0.19019577029155665, 'lstm_units_1': 117, 'lstm_units_2': 239}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.9975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:31:18,006] Trial 11 finished with value: 2.9974920749664307 and parameters: {'filters': 22, 'kernel_size': 3, 'dropout_rate': 0.18219990958561672, 'lstm_units_1': 125, 'lstm_units_2': 247}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.7533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:31:33,911] Trial 12 finished with value: 2.7532942295074463 and parameters: {'filters': 20, 'kernel_size': 3, 'dropout_rate': 0.1686977135551801, 'lstm_units_1': 128, 'lstm_units_2': 246}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.7033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:31:49,625] Trial 13 finished with value: 2.703263282775879 and parameters: {'filters': 26, 'kernel_size': 3, 'dropout_rate': 0.10367879462548793, 'lstm_units_1': 123, 'lstm_units_2': 256}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.9947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:32:05,194] Trial 14 finished with value: 2.9947094917297363 and parameters: {'filters': 27, 'kernel_size': 4, 'dropout_rate': 0.10897575924157302, 'lstm_units_1': 108, 'lstm_units_2': 207}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.1732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:32:21,239] Trial 15 finished with value: 3.1732466220855713 and parameters: {'filters': 30, 'kernel_size': 3, 'dropout_rate': 0.18653701639284836, 'lstm_units_1': 109, 'lstm_units_2': 213}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.0538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:32:37,799] Trial 16 finished with value: 3.053774356842041 and parameters: {'filters': 25, 'kernel_size': 3, 'dropout_rate': 0.1491053700020326, 'lstm_units_1': 111, 'lstm_units_2': 214}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:32:53,854] Trial 17 finished with value: 3.0622236728668213 and parameters: {'filters': 34, 'kernel_size': 4, 'dropout_rate': 0.22545611822612846, 'lstm_units_1': 100, 'lstm_units_2': 256}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.3792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:33:09,715] Trial 18 finished with value: 3.3792154788970947 and parameters: {'filters': 16, 'kernel_size': 3, 'dropout_rate': 0.22267089086622993, 'lstm_units_1': 119, 'lstm_units_2': 186}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.4894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:33:26,872] Trial 19 finished with value: 3.4893813133239746 and parameters: {'filters': 23, 'kernel_size': 4, 'dropout_rate': 0.10226308391332696, 'lstm_units_1': 98, 'lstm_units_2': 228}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.2651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:33:42,962] Trial 20 finished with value: 3.265113115310669 and parameters: {'filters': 30, 'kernel_size': 2, 'dropout_rate': 0.14857845702538544, 'lstm_units_1': 114, 'lstm_units_2': 195}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.0926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:33:59,094] Trial 21 finished with value: 3.0926437377929688 and parameters: {'filters': 20, 'kernel_size': 3, 'dropout_rate': 0.16564775754570277, 'lstm_units_1': 128, 'lstm_units_2': 235}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.8325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:34:15,402] Trial 22 finished with value: 2.8324508666992188 and parameters: {'filters': 20, 'kernel_size': 3, 'dropout_rate': 0.20688932405299093, 'lstm_units_1': 120, 'lstm_units_2': 236}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.7360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:34:32,375] Trial 23 finished with value: 2.7360053062438965 and parameters: {'filters': 27, 'kernel_size': 3, 'dropout_rate': 0.1420204833405228, 'lstm_units_1': 127, 'lstm_units_2': 247}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.1737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:34:50,035] Trial 24 finished with value: 3.1736764907836914 and parameters: {'filters': 27, 'kernel_size': 3, 'dropout_rate': 0.12647298284925526, 'lstm_units_1': 101, 'lstm_units_2': 220}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.8489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:35:05,885] Trial 25 finished with value: 3.848891019821167 and parameters: {'filters': 40, 'kernel_size': 4, 'dropout_rate': 0.2543086249155686, 'lstm_units_1': 117, 'lstm_units_2': 184}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:35:23,344] Trial 26 finished with value: 2.93996262550354 and parameters: {'filters': 64, 'kernel_size': 3, 'dropout_rate': 0.14017745159240308, 'lstm_units_1': 105, 'lstm_units_2': 253}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 28.3743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:35:38,881] Trial 27 finished with value: 28.374267578125 and parameters: {'filters': 33, 'kernel_size': 2, 'dropout_rate': 0.20069038818876286, 'lstm_units_1': 122, 'lstm_units_2': 46}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.1338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:35:55,760] Trial 28 finished with value: 3.133824110031128 and parameters: {'filters': 25, 'kernel_size': 3, 'dropout_rate': 0.13988941854332124, 'lstm_units_1': 115, 'lstm_units_2': 199}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.3671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:36:12,160] Trial 29 finished with value: 4.3670783042907715 and parameters: {'filters': 47, 'kernel_size': 4, 'dropout_rate': 0.3333120993882587, 'lstm_units_1': 49, 'lstm_units_2': 228}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.8190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:36:27,934] Trial 30 finished with value: 4.819016456604004 and parameters: {'filters': 28, 'kernel_size': 2, 'dropout_rate': 0.25411010290502833, 'lstm_units_1': 94, 'lstm_units_2': 165}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.8438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:36:44,898] Trial 31 finished with value: 2.8438291549682617 and parameters: {'filters': 19, 'kernel_size': 3, 'dropout_rate': 0.1694213192983166, 'lstm_units_1': 126, 'lstm_units_2': 238}. Best is trial 10 with value: 2.5998289585113525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.5961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:37:02,088] Trial 32 finished with value: 2.596050500869751 and parameters: {'filters': 23, 'kernel_size': 3, 'dropout_rate': 0.16742946843220874, 'lstm_units_1': 123, 'lstm_units_2': 256}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.7687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:37:19,605] Trial 33 finished with value: 2.7687339782714844 and parameters: {'filters': 24, 'kernel_size': 3, 'dropout_rate': 0.10148414621898622, 'lstm_units_1': 120, 'lstm_units_2': 251}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.3449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:37:39,028] Trial 34 finished with value: 3.3449292182922363 and parameters: {'filters': 40, 'kernel_size': 2, 'dropout_rate': 0.13265877263930648, 'lstm_units_1': 113, 'lstm_units_2': 223}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 15.3654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:37:54,790] Trial 35 finished with value: 15.365358352661133 and parameters: {'filters': 32, 'kernel_size': 3, 'dropout_rate': 0.20142303048570884, 'lstm_units_1': 104, 'lstm_units_2': 72}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.9880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:38:12,104] Trial 36 finished with value: 2.9879932403564453 and parameters: {'filters': 17, 'kernel_size': 2, 'dropout_rate': 0.382273006693036, 'lstm_units_1': 122, 'lstm_units_2': 239}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.8781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:38:28,699] Trial 37 finished with value: 2.878051519393921 and parameters: {'filters': 23, 'kernel_size': 3, 'dropout_rate': 0.24539493882356067, 'lstm_units_1': 93, 'lstm_units_2': 256}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.1319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:38:46,375] Trial 38 finished with value: 3.1319034099578857 and parameters: {'filters': 36, 'kernel_size': 4, 'dropout_rate': 0.12315789411318115, 'lstm_units_1': 116, 'lstm_units_2': 201}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.8680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:39:03,497] Trial 39 finished with value: 3.867968797683716 and parameters: {'filters': 27, 'kernel_size': 2, 'dropout_rate': 0.43972815344287997, 'lstm_units_1': 123, 'lstm_units_2': 180}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.9273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:39:22,126] Trial 40 finished with value: 3.9273273944854736 and parameters: {'filters': 43, 'kernel_size': 3, 'dropout_rate': 0.16797538901504563, 'lstm_units_1': 73, 'lstm_units_2': 227}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.6653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:39:40,764] Trial 41 finished with value: 2.6652519702911377 and parameters: {'filters': 21, 'kernel_size': 3, 'dropout_rate': 0.15838506018762896, 'lstm_units_1': 126, 'lstm_units_2': 243}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.9521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:39:58,181] Trial 42 finished with value: 2.952054738998413 and parameters: {'filters': 18, 'kernel_size': 3, 'dropout_rate': 0.15982241669368097, 'lstm_units_1': 128, 'lstm_units_2': 240}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.0451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:40:16,272] Trial 43 finished with value: 4.045124530792236 and parameters: {'filters': 22, 'kernel_size': 3, 'dropout_rate': 0.18333365147143643, 'lstm_units_1': 58, 'lstm_units_2': 245}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:40:34,060] Trial 44 finished with value: 3.0301079750061035 and parameters: {'filters': 29, 'kernel_size': 3, 'dropout_rate': 0.2694500512649539, 'lstm_units_1': 123, 'lstm_units_2': 216}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.7573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:40:54,270] Trial 45 finished with value: 2.757345676422119 and parameters: {'filters': 21, 'kernel_size': 3, 'dropout_rate': 0.12136662052147335, 'lstm_units_1': 109, 'lstm_units_2': 232}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.3902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:41:12,454] Trial 46 finished with value: 3.390226125717163 and parameters: {'filters': 26, 'kernel_size': 3, 'dropout_rate': 0.15028477748550306, 'lstm_units_1': 87, 'lstm_units_2': 244}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.3606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:41:30,047] Trial 47 finished with value: 3.3606109619140625 and parameters: {'filters': 31, 'kernel_size': 5, 'dropout_rate': 0.18543522310704036, 'lstm_units_1': 118, 'lstm_units_2': 208}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.6563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:41:47,528] Trial 48 finished with value: 4.656309604644775 and parameters: {'filters': 16, 'kernel_size': 3, 'dropout_rate': 0.21385263723452402, 'lstm_units_1': 125, 'lstm_units_2': 141}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.2682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:42:06,303] Trial 49 finished with value: 3.2682440280914307 and parameters: {'filters': 24, 'kernel_size': 4, 'dropout_rate': 0.3121702676090723, 'lstm_units_1': 113, 'lstm_units_2': 255}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:42:24,660] Trial 50 finished with value: 3.4444198608398438 and parameters: {'filters': 35, 'kernel_size': 4, 'dropout_rate': 0.11680147537456964, 'lstm_units_1': 106, 'lstm_units_2': 223}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.7081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:42:43,095] Trial 51 finished with value: 2.708111047744751 and parameters: {'filters': 19, 'kernel_size': 3, 'dropout_rate': 0.1745072755621734, 'lstm_units_1': 125, 'lstm_units_2': 246}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.7149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:43:01,661] Trial 52 finished with value: 2.714852809906006 and parameters: {'filters': 18, 'kernel_size': 3, 'dropout_rate': 0.19109544180298085, 'lstm_units_1': 128, 'lstm_units_2': 245}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.1905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:43:20,921] Trial 53 finished with value: 3.1905083656311035 and parameters: {'filters': 19, 'kernel_size': 3, 'dropout_rate': 0.23207206782677825, 'lstm_units_1': 119, 'lstm_units_2': 233}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.3241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:43:38,575] Trial 54 finished with value: 5.324057102203369 and parameters: {'filters': 22, 'kernel_size': 3, 'dropout_rate': 0.18993706016558082, 'lstm_units_1': 32, 'lstm_units_2': 246}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.7299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:43:56,908] Trial 55 finished with value: 2.729935646057129 and parameters: {'filters': 18, 'kernel_size': 3, 'dropout_rate': 0.17467541448910828, 'lstm_units_1': 124, 'lstm_units_2': 256}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.4907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:44:15,276] Trial 56 finished with value: 6.490710735321045 and parameters: {'filters': 21, 'kernel_size': 3, 'dropout_rate': 0.1565032313548498, 'lstm_units_1': 110, 'lstm_units_2': 123}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.2843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:44:33,741] Trial 57 finished with value: 3.2842841148376465 and parameters: {'filters': 16, 'kernel_size': 3, 'dropout_rate': 0.21586634595476895, 'lstm_units_1': 128, 'lstm_units_2': 218}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.9407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:44:54,558] Trial 58 finished with value: 2.940718650817871 and parameters: {'filters': 24, 'kernel_size': 2, 'dropout_rate': 0.19522849072346576, 'lstm_units_1': 117, 'lstm_units_2': 241}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.1550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:45:16,066] Trial 59 finished with value: 3.1549971103668213 and parameters: {'filters': 50, 'kernel_size': 3, 'dropout_rate': 0.28039401509528544, 'lstm_units_1': 121, 'lstm_units_2': 208}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.5811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:45:34,573] Trial 60 finished with value: 3.5811102390289307 and parameters: {'filters': 20, 'kernel_size': 4, 'dropout_rate': 0.23755652763753834, 'lstm_units_1': 112, 'lstm_units_2': 191}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.6018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:45:54,185] Trial 61 finished with value: 2.6018080711364746 and parameters: {'filters': 18, 'kernel_size': 3, 'dropout_rate': 0.172134525234806, 'lstm_units_1': 124, 'lstm_units_2': 249}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.8392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:46:13,131] Trial 62 finished with value: 2.8392419815063477 and parameters: {'filters': 17, 'kernel_size': 3, 'dropout_rate': 0.17460588589790843, 'lstm_units_1': 125, 'lstm_units_2': 232}. Best is trial 32 with value: 2.596050500869751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.5619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:46:33,125] Trial 63 finished with value: 2.561933755874634 and parameters: {'filters': 19, 'kernel_size': 3, 'dropout_rate': 0.13446864943825254, 'lstm_units_1': 120, 'lstm_units_2': 248}. Best is trial 63 with value: 2.561933755874634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.6541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:46:53,526] Trial 64 finished with value: 2.6541292667388916 and parameters: {'filters': 22, 'kernel_size': 3, 'dropout_rate': 0.1387238504920375, 'lstm_units_1': 116, 'lstm_units_2': 250}. Best is trial 63 with value: 2.561933755874634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.0962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:47:12,642] Trial 65 finished with value: 3.096208333969116 and parameters: {'filters': 25, 'kernel_size': 3, 'dropout_rate': 0.10984069791610261, 'lstm_units_1': 115, 'lstm_units_2': 237}. Best is trial 63 with value: 2.561933755874634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.7697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:47:31,513] Trial 66 finished with value: 2.7697322368621826 and parameters: {'filters': 22, 'kernel_size': 3, 'dropout_rate': 0.12897828566366898, 'lstm_units_1': 119, 'lstm_units_2': 250}. Best is trial 63 with value: 2.561933755874634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.9585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:47:51,475] Trial 67 finished with value: 2.9585235118865967 and parameters: {'filters': 29, 'kernel_size': 3, 'dropout_rate': 0.14086651703010883, 'lstm_units_1': 102, 'lstm_units_2': 227}. Best is trial 63 with value: 2.561933755874634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.7861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:48:10,604] Trial 68 finished with value: 2.786134958267212 and parameters: {'filters': 23, 'kernel_size': 3, 'dropout_rate': 0.15680474820793966, 'lstm_units_1': 107, 'lstm_units_2': 256}. Best is trial 63 with value: 2.561933755874634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.9074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:48:32,207] Trial 69 finished with value: 2.907437562942505 and parameters: {'filters': 56, 'kernel_size': 3, 'dropout_rate': 0.10052478698808605, 'lstm_units_1': 121, 'lstm_units_2': 248}. Best is trial 63 with value: 2.561933755874634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 14.0980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:48:51,697] Trial 70 finished with value: 14.098037719726562 and parameters: {'filters': 26, 'kernel_size': 2, 'dropout_rate': 0.13375856132110045, 'lstm_units_1': 38, 'lstm_units_2': 98}. Best is trial 63 with value: 2.561933755874634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.9007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:49:13,181] Trial 71 finished with value: 2.9006869792938232 and parameters: {'filters': 19, 'kernel_size': 3, 'dropout_rate': 0.14566932665359655, 'lstm_units_1': 124, 'lstm_units_2': 241}. Best is trial 63 with value: 2.561933755874634.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.5271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:49:34,636] Trial 72 finished with value: 2.5270566940307617 and parameters: {'filters': 21, 'kernel_size': 3, 'dropout_rate': 0.11567930528782996, 'lstm_units_1': 116, 'lstm_units_2': 249}. Best is trial 72 with value: 2.5270566940307617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.6336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:49:56,533] Trial 73 finished with value: 2.633575677871704 and parameters: {'filters': 21, 'kernel_size': 3, 'dropout_rate': 0.11393945827181373, 'lstm_units_1': 115, 'lstm_units_2': 234}. Best is trial 72 with value: 2.5270566940307617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.9891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:50:22,468] Trial 74 finished with value: 2.9891417026519775 and parameters: {'filters': 21, 'kernel_size': 3, 'dropout_rate': 0.1114220715288594, 'lstm_units_1': 111, 'lstm_units_2': 233}. Best is trial 72 with value: 2.5270566940307617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.2757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:50:42,986] Trial 75 finished with value: 3.275665760040283 and parameters: {'filters': 23, 'kernel_size': 3, 'dropout_rate': 0.12329268166869707, 'lstm_units_1': 115, 'lstm_units_2': 226}. Best is trial 72 with value: 2.5270566940307617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.9560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:51:03,590] Trial 76 finished with value: 2.9559712409973145 and parameters: {'filters': 21, 'kernel_size': 3, 'dropout_rate': 0.15648503180895812, 'lstm_units_1': 117, 'lstm_units_2': 213}. Best is trial 72 with value: 2.5270566940307617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.7210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:51:25,374] Trial 77 finished with value: 2.7210440635681152 and parameters: {'filters': 17, 'kernel_size': 3, 'dropout_rate': 0.13421663262597155, 'lstm_units_1': 98, 'lstm_units_2': 250}. Best is trial 72 with value: 2.5270566940307617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.1219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:51:46,825] Trial 78 finished with value: 3.121901035308838 and parameters: {'filters': 25, 'kernel_size': 3, 'dropout_rate': 0.11426608960379882, 'lstm_units_1': 112, 'lstm_units_2': 221}. Best is trial 72 with value: 2.5270566940307617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.7938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:52:07,948] Trial 79 finished with value: 2.793821334838867 and parameters: {'filters': 20, 'kernel_size': 3, 'dropout_rate': 0.14706522470769048, 'lstm_units_1': 121, 'lstm_units_2': 236}. Best is trial 72 with value: 2.5270566940307617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.0873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:52:29,044] Trial 80 finished with value: 3.0872955322265625 and parameters: {'filters': 28, 'kernel_size': 3, 'dropout_rate': 0.1635171082618699, 'lstm_units_1': 104, 'lstm_units_2': 250}. Best is trial 72 with value: 2.5270566940307617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.7654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:52:51,138] Trial 81 finished with value: 2.765439987182617 and parameters: {'filters': 22, 'kernel_size': 3, 'dropout_rate': 0.1278212184479353, 'lstm_units_1': 118, 'lstm_units_2': 241}. Best is trial 72 with value: 2.5270566940307617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.4855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:53:12,953] Trial 82 finished with value: 2.4855475425720215 and parameters: {'filters': 24, 'kernel_size': 3, 'dropout_rate': 0.10789921318760459, 'lstm_units_1': 122, 'lstm_units_2': 252}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.9932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:53:35,169] Trial 83 finished with value: 2.9932260513305664 and parameters: {'filters': 24, 'kernel_size': 3, 'dropout_rate': 0.11519478674146705, 'lstm_units_1': 114, 'lstm_units_2': 230}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 11.6542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:53:55,963] Trial 84 finished with value: 11.654186248779297 and parameters: {'filters': 18, 'kernel_size': 3, 'dropout_rate': 0.13722636680274344, 'lstm_units_1': 122, 'lstm_units_2': 81}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.0227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:54:18,209] Trial 85 finished with value: 3.0227177143096924 and parameters: {'filters': 20, 'kernel_size': 3, 'dropout_rate': 0.1510388893052222, 'lstm_units_1': 126, 'lstm_units_2': 242}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.8791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:54:39,857] Trial 86 finished with value: 2.879051446914673 and parameters: {'filters': 26, 'kernel_size': 3, 'dropout_rate': 0.12368188846805235, 'lstm_units_1': 108, 'lstm_units_2': 253}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.7565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:55:00,819] Trial 87 finished with value: 4.75647497177124 and parameters: {'filters': 23, 'kernel_size': 3, 'dropout_rate': 0.36204138371009764, 'lstm_units_1': 79, 'lstm_units_2': 162}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.8047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:55:23,382] Trial 88 finished with value: 2.804725170135498 and parameters: {'filters': 16, 'kernel_size': 3, 'dropout_rate': 0.10760817484420274, 'lstm_units_1': 116, 'lstm_units_2': 237}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:55:45,327] Trial 89 finished with value: 3.1162049770355225 and parameters: {'filters': 19, 'kernel_size': 3, 'dropout_rate': 0.16839023549660337, 'lstm_units_1': 119, 'lstm_units_2': 249}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.5805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:56:07,552] Trial 90 finished with value: 2.5805277824401855 and parameters: {'filters': 21, 'kernel_size': 3, 'dropout_rate': 0.1812563964848518, 'lstm_units_1': 126, 'lstm_units_2': 243}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:56:30,933] Trial 91 finished with value: 3.0076522827148438 and parameters: {'filters': 21, 'kernel_size': 3, 'dropout_rate': 0.20726104320295347, 'lstm_units_1': 123, 'lstm_units_2': 244}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.7146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:56:53,840] Trial 92 finished with value: 2.7145562171936035 and parameters: {'filters': 25, 'kernel_size': 3, 'dropout_rate': 0.17992168798203606, 'lstm_units_1': 127, 'lstm_units_2': 252}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:57:21,331] Trial 93 finished with value: 3.1003642082214355 and parameters: {'filters': 20, 'kernel_size': 3, 'dropout_rate': 0.10033957021595447, 'lstm_units_1': 121, 'lstm_units_2': 235}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.8378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:57:43,184] Trial 94 finished with value: 3.837799072265625 and parameters: {'filters': 22, 'kernel_size': 3, 'dropout_rate': 0.16175680823476954, 'lstm_units_1': 65, 'lstm_units_2': 227}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.6802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:58:05,398] Trial 95 finished with value: 2.6801652908325195 and parameters: {'filters': 18, 'kernel_size': 3, 'dropout_rate': 0.19934039190045372, 'lstm_units_1': 126, 'lstm_units_2': 245}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.8808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:58:27,669] Trial 96 finished with value: 2.8807802200317383 and parameters: {'filters': 17, 'kernel_size': 5, 'dropout_rate': 0.14106610205260897, 'lstm_units_1': 119, 'lstm_units_2': 238}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.8335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:58:49,672] Trial 97 finished with value: 2.833453893661499 and parameters: {'filters': 24, 'kernel_size': 3, 'dropout_rate': 0.1204280436488164, 'lstm_units_1': 124, 'lstm_units_2': 256}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.9717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:59:13,087] Trial 98 finished with value: 2.9717438220977783 and parameters: {'filters': 28, 'kernel_size': 4, 'dropout_rate': 0.15314692227015406, 'lstm_units_1': 114, 'lstm_units_2': 250}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.2175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-12 19:59:34,511] Trial 99 finished with value: 3.2175352573394775 and parameters: {'filters': 23, 'kernel_size': 3, 'dropout_rate': 0.1770101493212828, 'lstm_units_1': 116, 'lstm_units_2': 224}. Best is trial 82 with value: 2.4855475425720215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'filters': 24, 'kernel_size': 3, 'dropout_rate': 0.10789921318760459, 'lstm_units_1': 122, 'lstm_units_2': 252}\n"
     ]
    }
   ],
   "source": [
    "# hyper parameter tuning\n",
    "\n",
    "def create_model(trial):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Define the input shape in the first layer of the neural network\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    \n",
    "    # Add a Conv1D layer with hyperparameters\n",
    "    filters = trial.suggest_int('filters', 16, 64)\n",
    "    kernel_size = trial.suggest_int('kernel_size', 2, 5)\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, padding='same', input_shape=input_shape))\n",
    "\n",
    "    # Add a Dropout layer\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Add the first LSTM layer with hyperparameters\n",
    "    lstm_units_1 = trial.suggest_int('lstm_units_1', 32, 128)\n",
    "    model.add(LSTM(units=lstm_units_1, return_sequences=True))\n",
    "\n",
    "    # Add a Dropout layer\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Add the second LSTM layer with hyperparameters\n",
    "    lstm_units_2 = trial.suggest_int('lstm_units_2', 32, 256)\n",
    "    model.add(LSTM(units=lstm_units_2, return_sequences=True))\n",
    "\n",
    "    # Add a Dropout layer\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Add a Dense (fully connected) layer with 4 units (for 4 stats)\n",
    "    model.add(Dense(units=4))\n",
    "\n",
    "    # Compile the model with the custom weighted MSE loss\n",
    "    custom_loss = WeightedMSE(weights=[1.0, 0])\n",
    "    model.compile(optimizer='adam', loss=custom_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    \n",
    "    # Fit the model\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        validation_data=(X_test, y_test), \n",
    "                        epochs=100, \n",
    "                        batch_size=33, \n",
    "                        verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    \n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
